{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "diverse-council",
   "metadata": {},
   "source": [
    "# Seq2Seq 모델 구현 및 챗봇데이터 학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-relationship",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chatbot-torch clone\n",
    "!git clone https://github.com/Chat-with-U/chatbot-pytorch.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mobile-colony",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 497,
     "status": "ok",
     "timestamp": 1633011128941,
     "user": {
      "displayName": "Moonjong Shin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13586540763833363239"
     },
     "user_tz": -540
    },
    "id": "8wjmEXQ-5kiX",
    "outputId": "60e8760f-1436-4827-ecbd-faef02f4ff74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
      "remote: Enumerating objects: 91, done.\u001b[K\n",
      "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
      "remote: Compressing objects: 100% (85/85), done.\u001b[K\n",
      "remote: Total 91 (delta 43), reused 22 (delta 6), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (91/91), done.\n"
     ]
    }
   ],
   "source": [
    "#konlpy 설치\n",
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sophisticated-mustang",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 497,
     "status": "ok",
     "timestamp": 1633011128941,
     "user": {
      "displayName": "Moonjong Shin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13586540763833363239"
     },
     "user_tz": -540
    },
    "id": "8wjmEXQ-5kiX",
    "outputId": "60e8760f-1436-4827-ecbd-faef02f4ff74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
      "remote: Enumerating objects: 91, done.\u001b[K\n",
      "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
      "remote: Compressing objects: 100% (85/85), done.\u001b[K\n",
      "remote: Total 91 (delta 43), reused 22 (delta 6), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (91/91), done.\n"
     ]
    }
   ],
   "source": [
    "# mecab 설치 프로그램 clone\n",
    "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecological-accountability",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1633011128941,
     "user": {
      "displayName": "Moonjong Shin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13586540763833363239"
     },
     "user_tz": -540
    },
    "id": "eNQCVp-g3hIU",
    "outputId": "4c1004fd-eef1-4cd0-ca7f-2f933d01ee14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/Mecab-ko-for-Google-Colab\n"
     ]
    }
   ],
   "source": [
    "cd Mecab-ko-for-Google-Colab/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-knife",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 119298,
     "status": "ok",
     "timestamp": 1633011248237,
     "user": {
      "displayName": "Moonjong Shin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13586540763833363239"
     },
     "user_tz": -540
    },
    "id": "PM2U8CtR5qOJ",
    "outputId": "9ccafc8b-efa2-4dfc-f990-8e59deab8d7a"
   },
   "outputs": [],
   "source": [
    "# mecab 설치 프로그램 실행\n",
    "!bash install_mecab-ko_on_colab_light_210108.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "extreme-poker",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "import core.config as conf\n",
    "from konlpy.tag import Mecab  # tweepy오류로 konlpy 직접 설치 필요, mecab별도 설치 readme 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-tobago",
   "metadata": {},
   "source": [
    "가상 환경 생성<br> \n",
    "`conda create -n 가상환경이름 python=3.7`\n",
    "\n",
    "PyTorch(Windows, Conda, CUDA 10.2)<br>\n",
    "`conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "designing-iraqi",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-academy",
   "metadata": {},
   "source": [
    "# 데이터 전처리를 위한 설정\n",
    "Seq2Seq에서의 임베딩은 아래와 같이 추가 토큰을 사용하여 동작을 제어한다.\n",
    "\n",
    "- `<PAD>`: 0, Padding, 짧은 문장을 채울 때 사용하는 토큰\n",
    "- `<SOS>`: 1, Start of Sentence, 문장의 시작을 나타내는 토큰\n",
    "- `<EOS>`: 2, End of Sentence, 문장의 끝을 나타내는 토큰\n",
    "- `<UNK>`: 3, Unkown Words, 없는 단어를 나타내는 토큰\n",
    "\n",
    "디코더 입력에 <SOS>가 들어가면 디코딩(문장)의 시작을 의미하고 출력에 <EOS>가 나오면 디코딩(문장)을 종료한다.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wired-entertainment",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "considered-excellence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = conf.data_path\n",
    "chatbot_data = pd.read_csv(f'../dataset/ChatbotData.csv')\n",
    "chatbot_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "varied-graphic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 대화 쌍:  11823\n"
     ]
    }
   ],
   "source": [
    "print('총 대화 쌍: ', len(chatbot_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-september",
   "metadata": {},
   "source": [
    "두 사람의 대화를 가정할 때 대화를 시작하는 대화를 question, 대답을 answer라 명명하겠습니다\n",
    "\n",
    "이 챗봇의 경우 모든 대화를 1턴으로 가정하기 때문에 [대화 시작, 대답]을 대화의 끝으로 봅니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "secret-spotlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = chatbot_data.Q # Seq2Seq에 encoder_input\n",
    "answer = chatbot_data.A # Seq2Seq에 decoder_input\n",
    "total_utterances = pd.concat((question,answer)) #vocab을 만들기위한 전체 발화문장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-serbia",
   "metadata": {},
   "source": [
    "# 형태소분석\n",
    "\n",
    "챗봇 데이터 문장을 먼저 최소단위(우리말 형태소)로 tokenizing 해야합니다. 한국어는 KoNLPy라는 패키로 진행을 합니다.\n",
    "\n",
    "(해당 예시에서는 mecab 사용)\n",
    "(mecab외에도 Okt, komoran, kkma등 다른 형태소 분석기도 존재합니다. 각각 사용해보시고 차이점을 보는것도 재밌는 요소중 하나입니다)\n",
    "\n",
    "\n",
    "*최소단위(형태소)로 tokenizing한다는 이야기는 <span style=\"color:red\">형태소 단위로 문장을 쪼개는 것</span>을 의미합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "polished-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tagger = Mecab() #konlpy의 대표적인 형태소 분석기 mecab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-there",
   "metadata": {},
   "source": [
    "단어 임베딩 vocab을 만들기위해 아래와같이 단어별로 나눈 뒤 <span style=\"color:red\">vocab 리스트</span>에 넣어줍니다.\n",
    "\n",
    "vocab 리스트는 갖고있는 모든 데이터셋의 단어 집합이라고 생각하시면 됩니다.\n",
    "\n",
    "예를들어 갖고있는 문장이 \n",
    "\n",
    "<span style=\"color:blue\">'내가 그린 기린 그림은 긴 기린 그림이고 니가 그린 기린 그림은 짧은 기린 그림이다'</span> 한문장이라고 생각한다면\n",
    "\n",
    "vocab list는 [내가, 그린, 기린, 그림, 은 ,긴, 이고, 니가, 짧은, 이다] 가 될 수 있습니다\n",
    "\n",
    "vocab에는 중복되는 단어를 최소화 해야하며 vocab은 추후 정수 인코딩 부분에도 등장하기 때문에 개념을 잘 기억하고 넘어가는게 중요합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "documented-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = []\n",
    "\n",
    "special_tokens = ['[PAD]', '[MASK]', '[START]', '[END]', '[UNK]']\n",
    "for special_token in special_tokens:\n",
    "    vocab.append(special_token)\n",
    "\n",
    "for utterance in total_utterances:\n",
    "    for eojeols in pos_tagger.pos(utterance,flatten=False, join=True): # 대화를 형태소 분석기로 나눈 뒤 어절단위로 쪼갠 후\n",
    "        count = 0\n",
    "        for token in eojeols:\n",
    "            if count > 0:\n",
    "                if token in vocab:\n",
    "                    continue\n",
    "                vocab.append('##' + token) # 어절의 뒤에 나오는 형태소에 ##을 붙여 앞의 형태소와 이어지는 형태소임을 명시합니다. ex) 학교에 -> [학교, \"##에\"]\n",
    "            else:\n",
    "                if token in vocab:\n",
    "                    continue\n",
    "                vocab.append(token)\n",
    "                count += 1\n",
    "        \n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "english-permission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8665"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-growth",
   "metadata": {},
   "source": [
    "vocab_size는 만든 vocab이 몇개의 단어 혹은 형태소를 갖고있는가 나타내는 지표입니다.\n",
    "\n",
    "전체 11823개의 대화쌍의 데이터로 각 대화마다 2개의 문장이 존재한다고 하면 대략 2만4천개의 문장이 있다고 생각할 수 있습니다.\n",
    "\n",
    "즉 8665개의 단어/형태소를 이용하여 2만4천개의 문장을 표현할 수 있다는 것을 의미합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "located-philippines",
   "metadata": {},
   "source": [
    "# 토큰(단어/형태소) 인덱싱"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-slovenia",
   "metadata": {},
   "source": [
    "지금까지 형태소 분석기를 이용하여 우리가 갖고있는 데이터를 몇개의 형태소로 표현할 수 있는지 알아보았습니다.\n",
    "\n",
    "그렇다면 글자를 컴퓨터가 이해할 수 있는 숫자로 바꿔주는 작업이 필요합니다.\n",
    "\n",
    "그 첫번째 단계는 정수 인코딩 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-coast",
   "metadata": {},
   "source": [
    "정수 인코딩을 그림으로 표현하면 다음과 같습니다.\n",
    "\n",
    "<p align=\"center\"><img src=\"https://github.com/Chat-with-U/chatbot-study/blob/main/img/int_encoding.png?raw=true\"></p>\n",
    "\n",
    "vocab에는 단어에 맞는 index값이 있고 각 문장별로 단어를 vocab의 index로 매칭하는 과정을 거치게 됩니다.\n",
    "\n",
    "이는 추후 나오는 벡터화(vectorization)에서 다시한번 나오게 됩니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "magnetic-bottle",
   "metadata": {},
   "outputs": [],
   "source": [
    "token2index = {token : index for index, token in enumerate(vocab)} # token(형태소)을 key, index를 value로 두어 특정 형태소를 index로 변환하는 테이블을 만듭니다.\n",
    "index2token = {index : token for index, token in enumerate(vocab)} # 추후 모델을 통해 추론된 정수 index를 token(형태소)으로 변환하는 테이블을 만듭니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-morris",
   "metadata": {},
   "source": [
    "편의를 위해 WordHandler라는 클래스를 만들었습니다.\n",
    "\n",
    "클래스의 encode 부분은 문장을 vocab의 index로 변환하는 함수, decode는 인덱스를 문장으로 변환하는 과정을 수행하는 함수입니다.\n",
    "\n",
    "*decode without tag는 token뒤에 붙는 형태소 tag을 제거한 뒤 decode를 진행하는 함수입니다.\n",
    "\n",
    "하지만 max_seq_len의 역할은 무엇일까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-transcription",
   "metadata": {},
   "source": [
    "## max sequence length(최대 문장 길이)\n",
    "\n",
    "cats & dogs, mnist 모델을 구현해보시거나 다른 이미지 분류 테스크를 진행해보신 분들이라면 image resize의 측면으로 접근이 가능합니다.\n",
    "\n",
    "image분류 task에서 resize를 왜 진행하게 될까요? \n",
    "\n",
    "image의 사이즈가 제각기 다르다면 마지막으로 얻어낸 feature vector의 크기가 달라지게 되고 last feature map을 flatten했을 때 제각기 다른 parameter size를 갖게 될것입니다.\n",
    "\n",
    "때문에 image의 사이즈를 통일하여 마지막 feature map의 사이즈를 통일시켜주게 됩니다.\n",
    "\n",
    "NLP에선 max_seq_len가 이와 같은 역할을 하게됩니다.\n",
    "\n",
    "문장의 길이가 전부 제각각이고 짧은 문장, 긴 문장을 하나의 문장 크기로 조정해주는 역할을 하게됩니다.\n",
    "\n",
    "긴 문장은 max_seq_len보다 길다면 조금 자르고 짧은 문장은 앞서 정의한 '[PAD]' 토큰으로 채워주어 각 문장의 길이를 맞추어 모델에 동일한 input을 넣을 수 있도록 조정하는 역할을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "refined-discussion",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordHandler:\n",
    "    def __init__(self, vocab, pos_tagger, token2index, index2token):\n",
    "        self.vocab = vocab\n",
    "        self.pos_tagger = pos_tagger\n",
    "        self.token2index = token2index\n",
    "        self.index2token = index2token\n",
    "        \n",
    "    def encode(self, sentence):\n",
    "        encoded_vector = [self.token2index[token] if token in self.token2index else self.token2index['[UNK]']\n",
    "                          for token in self.pos_tagger.pos(sentence, join= True)]\n",
    "        \n",
    "        return encoded_vector\n",
    "    \n",
    "    def decode(self, indice, join=True):\n",
    "        decoded_vector = [self.index2token[index] for index in indice]\n",
    "        \n",
    "        return decoded_vector\n",
    "    \n",
    "    def decode_without_tag(self, indice):\n",
    "        decoded_vector = ' '.join([self.index2token[index].split('/')[0] for index in indice])\n",
    "        \n",
    "        return decoded_vector\n",
    "    \n",
    "    @staticmethod\n",
    "    def return_max_seq_len(sentences):\n",
    "        max_seq_len = 0\n",
    "        for sentence in sentences:\n",
    "            max_seq_len = max(len(sentence), max_seq_len)\n",
    "        \n",
    "        return max_seq_len \n",
    "    \n",
    "    # 이 handler는 주어진 데이터셋에서 가장 긴 문장길이를 max_seq_len로 return합니다.\n",
    "    # 따라서 긴 길이의 문장이 잘려 손실이 발생하진 않지만 짧은 문장은 거의 [PAD]토큰으로 채워질 수 있습니다.\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-evans",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "Seq2Seq 모델로 데이터를 전달하기 위한 Dataset을 구현하였습니다.\n",
    "\n",
    "문장의 첫번째에 [START]토큰을 넣고 끝에 [END]토큰을 넣어 문장의 시작과 끝을 모델에 알려줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "sealed-technique",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChitChatDataset(Dataset):\n",
    "    def __init__(self, input_ids, output_ids, index2token, token2index, max_seq_len):\n",
    "        self.input_ids = input_ids\n",
    "        self.output_ids = output_ids\n",
    "        self.index2token = index2token\n",
    "        self.token2index = token2index\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if len(self.input_ids[idx]) + 2 < self.max_seq_len:\n",
    "            padding_block = self.max_seq_len - len(self.input_ids[idx]) + 2\n",
    "            input = torch.LongTensor([self.token2index['[START]']] + \n",
    "                                     self.input_ids[idx] + \n",
    "                                     [self.token2index['[END]']] + \n",
    "                                     [self.token2index['[PAD]']] * padding_block)\n",
    "        else:\n",
    "            input = torch.LongTensor([self.token2index['[START]']] + \n",
    "                                     self.input_ids[idx] + \n",
    "                                     [self.token2index['[END]']])\n",
    "        \n",
    "        if len(self.output_ids[idx]) + 2 < self.max_seq_len:\n",
    "            padding_block = self.max_seq_len - len(self.output_ids[idx]) + 2\n",
    "            output = torch.LongTensor([self.token2index['[START]']]+\n",
    "                                      self.output_ids[idx] + \n",
    "                                     [self.token2index['[END]']] + \n",
    "                                     [self.token2index['[PAD]']] * padding_block )\n",
    "        else:\n",
    "            output = torch.LongTensor([self.token2index['[START]']] +\n",
    "                                      self.output_ids[idx] + \n",
    "                                     [self.token2index['[END]']])\n",
    "\n",
    "        return input, output\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "narrow-permit",
   "metadata": {},
   "outputs": [],
   "source": [
    "handler = WordHandler(vocab, pos_tagger, token2index, index2token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-international",
   "metadata": {},
   "source": [
    "모델에 들어갈 input과 output을 정의합니다.\n",
    "\n",
    "input은 대화의 시작, output은 그에대한 대답으로 이루어집니다.\n",
    "\n",
    "따라서 우리가 대화를 시작하면 챗봇은 그에 대한 대답을 하도록 학습되어지게 만들어집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "regional-gospel",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = question.map(handler.encode)\n",
    "output_ids = answer.map(handler.encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "representative-france",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 대화:  SNS 보 면 나 만 빼 고 다 행복 해 보여\n",
      "챗봇의 대답:  자랑 하 는 자리 니까요 .\n"
     ]
    }
   ],
   "source": [
    "print('사용자 대화: ', handler.decode_without_tag(input_ids[10]))\n",
    "print('챗봇의 대답: ', handler.decode_without_tag(output_ids[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "least-camel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_len = max(handler.return_max_seq_len(output_ids), handler.return_max_seq_len(input_ids))\n",
    "max_seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-edwards",
   "metadata": {},
   "source": [
    "max_seq_len가 40이 나왔지만 조금 더 길게 대답하도록 만들어볼까요?\n",
    "\n",
    "max_seq_len를 60으로 설정해보겠습니다.\n",
    "\n",
    "물론 max_seq_len를 길게 설정한다고 모든 모델이 긴 대답을 하는 것은 아닙니다. 오히려 [PAD]토큰을 보는 빈도가 늘고 챗봇의 output이 [PAD]로 채우기만해도 loss가 떨어지는 현상이 발생할 가능성이 있습니다.\n",
    "\n",
    "하지만 길게 설정되면 어떤 결과를 가져올까요? 여러분이 직접 조절해가며 결과와 loss값을 확인하는것도 재밌는 요소중 하나가 될것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "polar-defensive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset정의\n",
    "chitchat_data = ChitChatDataset(input_ids, output_ids, index2token, token2index, 60)\n",
    "# Dataloader 정의\n",
    "chichat_dataloader = DataLoader(chitchat_data, batch_size= 100, shuffle = True)\n",
    "\n",
    "#학습 device 정의\n",
    "device = 'cuda:1' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cf2a2ee2-4fdd-4f7c-a2f5-d48f3a164548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8665"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(handler.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7b987179-05f0-4266-aa53-c9a407355977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[START] 하루 가 또 가 네요 . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handler.decode_without_tag(chitchat_data[0][1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-samuel",
   "metadata": {},
   "source": [
    "아래의 코드는 Seq2Seq모델을 정의하는 부분입니다.\n",
    "\n",
    "자세한 설명은 [링크]를 참조하세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fitted-thanksgiving",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(LSTMEncoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(embedding_dim, embedding_dim, num_layers=1 ,batch_first=True, dropout=0.3)\n",
    "\n",
    "    def forward(self, encoder_embeds):\n",
    "        encoder_output, hidden_and_cell = self.lstm(encoder_embeds)\n",
    "        \n",
    "        return encoder_output, hidden_and_cell\n",
    "\n",
    "    \n",
    "class LSTMDecoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, use_attention):\n",
    "        super(LSTMDecoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(embedding_dim, embedding_dim, num_layers=1 ,batch_first=True, dropout=0.3)\n",
    "        self.softmax_score = nn.Softmax(-1)\n",
    "        self.use_attention = use_attention\n",
    "\n",
    "\n",
    "    def forward(self, decoder_embeds, hidden_and_cell, encoder_output=None):\n",
    "        \n",
    "        time_step = decoder_embeds.size()[1]\n",
    "        decoder_lstm_output = torch.zeros_like(decoder_embeds) # [Batch, max_seq_len, hidden_dim]\\\n",
    "    \n",
    "        \n",
    "        if self.use_attention:\n",
    "            attention_representation = torch.zeros_like(encoder_output) # [Batch, max_seq_len, hidden_dim]\n",
    "            transposed_encode_hidden = torch.transpose(encoder_output, 1, 2) # [Batch, hidden_dim, max_seq_len]\n",
    "            \n",
    "            for step, i in enumerate(range(time_step)):\n",
    "                \n",
    "                if step == 0:\n",
    "                    decoder_vector_step, h_and_c = self.lstm(decoder_embeds[:, i, :].unsqueeze(1), hidden_and_cell) # [Batch, 1, hidden_dim]\n",
    "                else:\n",
    "                    decoder_vector_step, h_and_c = self.lstm(decoder_vector_step, h_and_c)\n",
    "                        \n",
    "                \n",
    "                softmax_attention  = self.softmax_score(torch.bmm(decoder_vector_step, transposed_encode_hidden)) # [Batch, 1, max_seq_len]\n",
    "                attention_dim = torch.bmm(softmax_attention, encoder_output) # [Bach, 1, hidden]\n",
    "                attention_representation[:, i, :] = attention_dim.squeeze(1)\n",
    "                decoder_lstm_output[:, i, :] = decoder_vector_step.squeeze(1)\n",
    "                \n",
    "                \n",
    "            output = torch.cat([decoder_lstm_output, attention_representation], -1)\n",
    "            \n",
    "        else:\n",
    "            for step, i in enumerate(range(time_step)):\n",
    "                \n",
    "                if step == 0:\n",
    "                    decoder_vector_step, h_and_c = self.lstm(decoder_embeds[:, i, :].unsqueeze(1), hidden_and_cell) # [Batch, 1, hidden_dim]\n",
    "                else:\n",
    "                     decoder_vector_step, h_and_c = self.lstm(decoder_vector_step, h_and_c)\n",
    "                    \n",
    "                decoder_lstm_output[:, i, :] = decoder_vector_step.squeeze(1)\n",
    "            \n",
    "            \n",
    "        return output\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, use_attention=None, is_test=None):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.word_embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.encoder = LSTMEncoder(embedding_dim)\n",
    "        self.decoder = LSTMDecoder(embedding_dim, use_attention)\n",
    "        self.vocab_proj = nn.Linear(embedding_dim, vocab_size)\n",
    "        \n",
    "        if use_attention:\n",
    "            self.vocab_proj = nn.Linear(embedding_dim * 2, vocab_size)\n",
    "        self.use_attention = use_attention\n",
    "\n",
    "    def forward(self, encode_input, decode_input):\n",
    "        encoder_embeds = self.word_embedding(encode_input)\n",
    "        decoder_embeds = self.word_embedding(decode_input)\n",
    "        \n",
    "        encoder_output, hidden_and_cell = self.encoder(encoder_embeds)\n",
    "        decoder_output = self.decoder(decoder_embeds, hidden_and_cell, encoder_output)\n",
    "        \n",
    "        projected_output = self.vocab_proj(decoder_output)\n",
    "        \n",
    "        return projected_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-temperature",
   "metadata": {},
   "source": [
    "자 이제 학습을 위한 모든 준비가 끝났습니다. 과연 여러분의 챗봇은 어떤 대답을 하게될까요?\n",
    "\n",
    "직접 확인해보시죠!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a89231-4181-4d59-ad78-69cd38d036f9",
   "metadata": {},
   "source": [
    "# seq2seq without attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422dbc59-928d-46a6-a4ad-d2c9862d89c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "model = Seq2Seq(vocab_size, 512).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.0001\n",
    "optimizer = Adam(model.parameters(), lr)\n",
    "step = 0\n",
    "\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(100)):\n",
    "    for encode_input, decode_input in tqdm(chichat_dataloader):\n",
    "        encode_input = encode_input.to(device)\n",
    "        decode_input = decode_input.to(device)\n",
    "\n",
    "        step += 1\n",
    "        optimizer.zero_grad()\n",
    "        output = model(encode_input, decode_input)\n",
    "        \n",
    "        loss = 0\n",
    "        for i in range(output.size()[0]):\n",
    "            loss += criterion(output[i][:len(decode_input[i])], decode_input[i])\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        sample_input = handler.decode_without_tag(encode_input[0][encode_input[0] != 0].tolist())\n",
    "        sample_output = handler.decode_without_tag(output[0].argmax(-1)[output[0].argmax(-1) != 0].tolist())\n",
    "        print(f'loss: {loss}')\n",
    "        print(f'input_sentence: {sample_input}')\n",
    "        print(f'output_sentence: {sample_output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6536c200-b94f-4d02-8958-4a67d215c7e4",
   "metadata": {},
   "source": [
    "# seq2seq with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "db7cea5b-0f90-4944-a7af-0e6de0ddbebe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/moonjong/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43c05a54f6544ecdb097b1770e9ceb3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd99163cb7a44e8c80edbc4c45ab946a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 22.05413246154785\n",
      "input_sentence: [START] 후 . 언제 까지 [UNK] [END]\n",
      "output_sentence: [START] [UNK] 이 . . . .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9d69016873b43eaa53a73c4b073ddfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca7484c2f32e46f68e6619ee596d4eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f1b49ed05f4ebe9f71992beb2330ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dc2e81077554c0683b9985783d6c066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "026b7c32ff834981b8b7e5354a532c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3d163a7fa042d88269271052670811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfde9d7669c94ce49f65a1247fc996c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2dbaba50aba4c2288b20e8a6ae49ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f1189468d44989bebf032063ffe500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "059caefa17594157ac9e953d0bb81fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 15.469898223876953\n",
      "input_sentence: [START] 나 의 약점 [END]\n",
      "output_sentence: [START] [UNK] 이 . . .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d4d4b5102f487f9c06bcf8cfcc7690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84531996b2584f58a3a28f52f04fd305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4627c1ce77794c9c8aaf54d538359b03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4589d67b2ef148fa8011bc8a69945445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a7bb28d66c0478c8ebdc43e0def0f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e12d3f2a50849f892fb7aa854011a11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a376500dac47269ba9dd45bf41f68e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b55ca83c4434d77875467a346b697ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9520ca83c7374ada91fda5092e722755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14761112b809421ebe535081461af802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 7.60088586807251\n",
      "input_sentence: [START] 친한 친구 랑 싸웠 어 [END]\n",
      "output_sentence: [START] 사과 라면 들 사과 보 세요 세요 [END]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed1030e55b74c10a514b13e99aa8f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ed3fea6d58240b281de6ec510a8c70c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "098326f25e6f41ad8027bcbf8fbeab93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "047b95d96ca5449ba41ee5ac4accfed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9d3ff5fab114d308f03195d466b0522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3481ceb5af40d2afe07ca14e6defe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7e7a1d185ff4b659eab5853d34e0ce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b0cba61c6804e02aeaa48330506a547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d68102041f354a57b4be18c8e74e8d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ec8e7e30ec48a6874d042f2216615a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 4.050048828125\n",
      "input_sentence: [START] 용돈 다 썼 어 [END]\n",
      "output_sentence: [START] 올려 바 해 보 세요 . [END] [END]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ebdc67c481549be8fac5a9736b7fee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104fa5d4d25d4aca87e4e044662b9026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6be1a1cb7d2f40b68b84799878569e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb11f244c6a24d6896334ae458b5fd97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c269ee15f634cee8155c6639a9805d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbdf67d6f8bc48699c6c54eae5164757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db95309b28ae43f7b462eaadc43302c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebfa8b96cfaf4437aa523446ad17247f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "722fe9ca4206428eb76a21bbb250f64f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1590f501fae4be4adbb6750ba9c0287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 3.471297025680542\n",
      "input_sentence: [START] 결혼 은 타이밍 인가 ? [END]\n",
      "output_sentence: [START] 결혼 뿐 은 아니 은 은 은 타이밍 인생 연속 은 . . [END]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff46afbf01e41bf9ba213cd800df7b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b1449fefba245ca88db5c9b4de8b29f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89fd33ec2bad41d2b0083947e766224e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd0a5b96e424f3f97fdbc8085638991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d498593d353648a38bc50125d2203abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "726eb571eadf4c9190eff6acb56e68c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9d6e1924a454bd0adef6ee2bd2b8829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c4c1d3f8fbe4728b129c2609ac07300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcc3dab44f1d45f1aef7dd2b93f9d2b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "946322e4ac20430e9abc85ce2216b1c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.7289892435073853\n",
      "input_sentence: [START] 온종일 [UNK] 하 네 [END]\n",
      "output_sentence: [START] 이런 날 더욱 적적 하 지요 . [END]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3beddd622fdd4ef1a6ad26068e22d979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "190e06ac5e574abfa44ace2a30065783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f7d00a661c4fdb9cd03b16bfb71ea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14cd23d80f0f44d3af747c519a33169e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a83bc0852d504d598a73bc33c7c7947c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4388e1875d354a3990d78ffd4b66213f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50091a3e11d3424688284abc9f3940ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a759ff30c5c4ddf9ac1736d7d811f3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f448a9f75264f97a2d930ee714bc453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd2b9da060f745989aa6b896ee9d1fdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.0411313772201538\n",
      "input_sentence: [START] 신경 이 바늘 끝 같 아 [END]\n",
      "output_sentence: [START] 너무 신경 곤두세우 지 마세요 . [END]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "532789773c5f4bdd85ae9610e1436e01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e542bb1e94b54a1b8f0ca71c3077a7e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4371e4b5e78f4bff89ceba062f79fcf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6ab71a2931947158044d408b17433df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7fc3596233a41bab4acabb3b1290846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28c89db1a52e4a7b99748d8dded333f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f421636e3b4c08b775cc9610ccb4bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e1ba8f869348bf9dde46328720b5d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1038d3114fd34f7b998694908e2fcd74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb6439f80c544369c89b66e47c887ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.322023868560791\n",
      "input_sentence: [START] 진짜 사랑 해서 아픈 느낌 . [END]\n",
      "output_sentence: [START] 가늠 도 안 될 정도 로 힘들 죠 . [END]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f318ae63e994307ac0fc32e75bb7f4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8646026342514253b7bc54c9b709e300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f388e33e35346ba931d3401d4a685f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ffd79262124ba8adfd5843dd2eac33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f126f7db85426cbba65802be3d1658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40fb93e291214cff9a46e7eb8bc1dd9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c6b6597de54e3a8a7c12fe152e1c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbab55c544414dacb489a7bd3d4bd453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38277ee353504a4c8af28ce696804a4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d01d89ccf23948f6a38684dc121a4a13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5229498744010925\n",
      "input_sentence: [START] 집 까지 데려다 줬 는데 호감 ? 그냥 매너 ? [END]\n",
      "output_sentence: [START] 호감 이 있 을 수 도 있 어요 . [UNK] 조금 더 상황 을 지켜보 세요 세요\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff2b3ee3282e4d76a80307693c423aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e722491562674017a3b54ec52411fc96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2793513b4cc4aa79cd70eac27c586be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "907b5766d9ba4f07bf6fed9cb92e0735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3218ba2af75549eca82baf19bf1c75e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f00c524fb9f243de9bc6980e2a3a401e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44de99feb5c74326bcde9de457f45bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3466122c82564bc98cf396368ae6919d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3947a61ae98e47fc865a8294ceab85ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ed74db39e54268b2fab916ebda8eb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.121755599975586\n",
      "input_sentence: [START] 1 년 째 동거 중 이 야 [END]\n",
      "output_sentence: [START] 서로 알 아 가 는 단계 인가 봐요 . [END]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a23ecb3416884b0daae0b1d65f89cc80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e44cbf6ba02486d96ea54c6ea5b2205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "355d03ef3e2a439a9d17a90edf3e3ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9caf036444924efca95fdca6f8df034c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c516e4f984c49b299878426180aa817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef2f410c7a764a26acd96e6498389bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c25b8b8503b04cdb9b9c83036bea0aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ebe0d47058840f2909459e06bd8bfd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd2a8dbba7b54d93a4385a308fe51450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Seq2Seq(vocab_size, 512, use_attention=True).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.001\n",
    "optimizer = Adam(model.parameters(), lr)\n",
    "step = 0\n",
    "\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(100)):\n",
    "    for encode_input, decode_input in tqdm(chichat_dataloader):\n",
    "        encode_input = encode_input.to(device)\n",
    "        decode_input = decode_input.to(device)\n",
    "        \n",
    "        step += 1\n",
    "        optimizer.zero_grad()\n",
    "        projected_output = model(encode_input, decode_input)\n",
    "        \n",
    "        loss = 0\n",
    "        for i in range(projected_output.size()[0]):\n",
    "            loss += criterion(projected_output[i][:len(decode_input[i])], decode_input[i])\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        sample_input = handler.decode_without_tag(encode_input[0][encode_input[0] != 0].tolist())\n",
    "        sample_output = handler.decode_without_tag(projected_output[0].argmax(-1)[projected_output[0].argmax(-1) != 0].tolist())\n",
    "        print(f'loss: {loss}')\n",
    "        print(f'input_sentence: {sample_input}')\n",
    "        print(f'output_sentence: {sample_output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e7bbccfd-f054-4c68-8d36-af07a7498bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sentence2input(sentence):\n",
    "    input_ids = handler.encode(sentence)\n",
    "    if len(input_ids) + 2 < 60:\n",
    "        padding_block = max_seq_len - len(input_ids) + 2\n",
    "        input = torch.LongTensor([token2index['[START]']] + \n",
    "                                 input_ids + \n",
    "                                 [token2index['[END]']] + \n",
    "                                 [token2index['[PAD]']] * padding_block)\n",
    "    else:\n",
    "        input = torch.LongTensor([token2index['[START]']] + \n",
    "                                 input_ids + \n",
    "                                 [token2index['[END]']])\n",
    "\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2986c7a4-5e5d-4456-8c7d-d5416405b066",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "챗봇에게 말을 걸어보세요 :  넌 좀 더 배워야겠다\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[START] 부족 에 내 은 지 이 . . [END]'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentence = input('챗봇에게 말을 걸어보세요 : ')\n",
    "dummy_decode_input = make_sentence2input('').unsqueeze(0)\n",
    "\n",
    "input_tensor = make_sentence2input(input_sentence).unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    dummy_decode_input = dummy_decode_input.to(device)\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    \n",
    "    logit = model(input_tensor, dummy_decode_input)\n",
    "    sample_output = handler.decode_without_tag(logit[0].argmax(-1)[logit[0].argmax(-1) != 0].tolist())\n",
    "    \n",
    "sample_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5376e687-6cb0-4415-b0b9-3bd3c8d48e51",
   "metadata": {},
   "source": [
    "Attention을 사용하여 생성한 모델의 loss가 훨씬 빠르게 수렴하는 것을 확인할 수 있습니다.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moonjong",
   "language": "python",
   "name": "moonjong"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
