{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "civil-buddy",
   "metadata": {},
   "source": [
    "# Seq2Seq 모델 구현 및 챗봇데이터 학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "understanding-luther",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "\n",
    "class LSTMDecoder(nn.Module):\n",
    "    def __init__(self, num_classes=18):\n",
    "        super(LSTMDecoder, self).__init__()\n",
    "        self.net = nn.Conv2d()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class LSTMEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, output_dim):\n",
    "        super(LSTMEncoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=512, hidden_size=1024, num_layers=2 ,batch_first=True)\n",
    "\n",
    "    def forward(self, embedded_ids):\n",
    "        last_hidden_state = self.lstm(embedded_ids)[1][0]\n",
    "        return last_hidden_state\n",
    "\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, output_dim):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.word_embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.encoder = LSTMEncoder(embedding_dim, output_dim)\n",
    "        self.decoer = LSTMDecoder(embedding_dim, output_dim)\n",
    "\n",
    "    def forward(self, input_ids, output_ids):\n",
    "        embedded_ids = self.word_embedding(input_ids)\n",
    "        \n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "editorial-acquisition",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot_data = pd.read_csv('../chatbot_data/ChatbotData.csv')\n",
    "chatbot_data\n",
    "\n",
    "#형태소 분석기 호출 -> 형태소 별로 단어를 나누고 이를 set으로 만들어 vocab생성\n",
    "pos_tagger = Mecab()\n",
    "\n",
    "question = chatbot_data.Q # Seq2Seq에 encoder_input\n",
    "answer = chatbot_data.A # Seq2Seq에 decoder_input\n",
    "total_utterances = pd.concat((question,answer)) #vocab을 만들기위한 전체 발화문장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-tractor",
   "metadata": {},
   "source": [
    "단어 임베딩 vocab을 만들기위해 아래와같이 단어별로 나눈 뒤 vocab set에 넣어줍니다.\n",
    "\n",
    "set에 add되기때문에 중복되는 vocab은 존재하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "equivalent-scheme",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = []\n",
    "\n",
    "special_tokens = ['[PAD]', '[MASK]', '[START]', '[END]', '[UNK]']\n",
    "for special_token in special_tokens:\n",
    "    vocab.append(special_token)\n",
    "\n",
    "for utterance in total_utterances:\n",
    "    for eojeols in pos_tagger.pos(utterance,flatten=False, join=True):\n",
    "        count = 0\n",
    "        for token in eojeols:\n",
    "            if count > 0:\n",
    "                if token in vocab:\n",
    "                    continue\n",
    "                vocab.append('##' + token)\n",
    "            else:\n",
    "                if token in vocab:\n",
    "                    continue\n",
    "                vocab.append(token)\n",
    "                count += 1\n",
    "        \n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "essential-timeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "token2index = {token : index for index, token in enumerate(vocab)}\n",
    "index2token = {index : token for index, token in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "flying-current",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "medical-brand",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordHandler:\n",
    "    def __init__(self, vocab, pos_tagger, token2index, index2token):\n",
    "        self.vocab = vocab\n",
    "        self.pos_tagger = pos_tagger\n",
    "        self.token2index = token2index\n",
    "        self.index2token = index2token\n",
    "        \n",
    "    def encode(self, sentence):\n",
    "        encoded_vector = [self.token2index[token] if token in self.token2index else self.token2index['[UNK]']\n",
    "                          for token in self.pos_tagger.pos(sentence, join= True)]\n",
    "        \n",
    "        return encoded_vector\n",
    "    \n",
    "    def decode(self, indice, join=True):\n",
    "        decoded_vector = [self.index2token[index] for index in indice]\n",
    "        \n",
    "        return decoded_vector\n",
    "    \n",
    "    def decode_without_tag(self, indice):\n",
    "        decoded_vector = ' '.join([self.index2token[index].split('/')[0] for index in indice])\n",
    "        \n",
    "        return decoded_vector\n",
    "    \n",
    "    @staticmethod\n",
    "    def return_max_seq_len(sentences):\n",
    "        max_seq_len = 0\n",
    "        for sentence in sentences:\n",
    "            max_seq_len = max(len(sentence), max_seq_len)\n",
    "        \n",
    "        return max_seq_len\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "conventional-shelf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChitChatDataset(Dataset):\n",
    "    def __init__(self, input_ids, output_ids, index2token, token2index, max_seq_len):\n",
    "        self.input_ids = input_ids\n",
    "        self.output_ids = output_ids\n",
    "        self.index2token = index2token\n",
    "        self.token2index = token2index\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if len(self.input_ids[idx]) + 2 < self.max_seq_len:\n",
    "            padding_block = self.max_seq_len - len(self.input_ids[idx]) + 2\n",
    "            input = torch.LongTensor([self.token2index['[START]']] + \n",
    "                                     self.input_ids[idx] + \n",
    "                                     [self.token2index['[END]']] + \n",
    "                                     [self.token2index['[PAD]']] * padding_block)\n",
    "        else:\n",
    "            input = torch.LongTensor([self.token2index['[START]']] + \n",
    "                                     self.input_ids[idx] + \n",
    "                                     [self.token2index['[END]']])\n",
    "        \n",
    "        if len(self.output_ids[idx]) + 2 < self.max_seq_len:\n",
    "            padding_block = self.max_seq_len - len(self.output_ids[idx]) + 2\n",
    "            output = torch.LongTensor([self.token2index['[START]']] + \n",
    "                                     self.output_ids[idx] + \n",
    "                                     [self.token2index['[END]']] + \n",
    "                                     [self.token2index['[PAD]']] * padding_block)\n",
    "        else:\n",
    "            output = torch.LongTensor([self.token2index['[START]']] + \n",
    "                                     self.output_ids[idx] + \n",
    "                                     [self.token2index['[END]']])\n",
    "\n",
    "        return input, output\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "illegal-gravity",
   "metadata": {},
   "outputs": [],
   "source": [
    "handler = WordHandler(vocab, pos_tagger, token2index, index2token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "actual-protein",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ids = question.map(handler.encode)\n",
    "input_ids = answer.map(handler.encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "saved-large",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_len = max(handler.return_max_seq_len(output_ids), handler.return_max_seq_len(input_ids))\n",
    "max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "complimentary-holly",
   "metadata": {},
   "outputs": [],
   "source": [
    "chitchat_data = ChitChatDataset(input_ids, output_ids, index2token, token2index, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "lucky-census",
   "metadata": {},
   "outputs": [],
   "source": [
    "chichat_dataloader = DataLoader(chitchat_data, batch_size= 10, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "juvenile-commodity",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input, output in chichat_dataloader:\n",
    "    a = embedding(input)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
